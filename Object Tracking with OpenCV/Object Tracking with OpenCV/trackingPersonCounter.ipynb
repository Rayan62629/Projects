{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n",
      "[INFO] starting video stream...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\MITS MAIN\\MITS\\DataScience\\PROJECTS\\Simple-object-tracking-with-OpenCV-master\\Simple-object-tracking-with-OpenCV-master\\trackingPersonCounter.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MITS%20MAIN/MITS/DataScience/PROJECTS/Simple-object-tracking-with-OpenCV-master/Simple-object-tracking-with-OpenCV-master/trackingPersonCounter.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MITS%20MAIN/MITS/DataScience/PROJECTS/Simple-object-tracking-with-OpenCV-master/Simple-object-tracking-with-OpenCV-master/trackingPersonCounter.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# read the next frame from the video stream and resize it\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MITS%20MAIN/MITS/DataScience/PROJECTS/Simple-object-tracking-with-OpenCV-master/Simple-object-tracking-with-OpenCV-master/trackingPersonCounter.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     frame \u001b[39m=\u001b[39m vs\u001b[39m.\u001b[39mread()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MITS%20MAIN/MITS/DataScience/PROJECTS/Simple-object-tracking-with-OpenCV-master/Simple-object-tracking-with-OpenCV-master/trackingPersonCounter.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     frame \u001b[39m=\u001b[39m imutils\u001b[39m.\u001b[39;49mresize(frame, width\u001b[39m=\u001b[39;49m\u001b[39m400\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MITS%20MAIN/MITS/DataScience/PROJECTS/Simple-object-tracking-with-OpenCV-master/Simple-object-tracking-with-OpenCV-master/trackingPersonCounter.ipynb#W0sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m# if the frame dimensions are None, grab them\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MITS%20MAIN/MITS/DataScience/PROJECTS/Simple-object-tracking-with-OpenCV-master/Simple-object-tracking-with-OpenCV-master/trackingPersonCounter.ipynb#W0sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mif\u001b[39;00m W \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m H \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Abdul vaseem siddiqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imutils\\convenience.py:69\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(image, width, height, inter)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresize\u001b[39m(image, width\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, height\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, inter\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_AREA):\n\u001b[0;32m     66\u001b[0m     \u001b[39m# initialize the dimensions of the image to be resized and\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39m# grab the image size\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     dim \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     (h, w) \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mshape[:\u001b[39m2\u001b[39m]\n\u001b[0;32m     71\u001b[0m     \u001b[39m# if both the width and height are None, then return the\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[39m# original image\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m width \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m height \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from pyimagesearch.centroidtracker import CentroidTracker\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# Manually set the values for prototxt, model, and confidence\n",
    "prototxt = \"./deploy.prototxt\"\n",
    "model = \"./res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "confidence = 0.5\n",
    "\n",
    "# initialize our centroid tracker and frame dimensions\n",
    "ct = CentroidTracker()\n",
    "(H, W) = (None, None)\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt, model)\n",
    "\n",
    "# initialize the video stream and allow the camera sensor to warmup\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "    # read the next frame from the video stream and resize it\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "\n",
    "    # if the frame dimensions are None, grab them\n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "    # construct a blob from the frame, pass it through the network,\n",
    "    # obtain our output predictions, and initialize the list of\n",
    "    # bounding box rectangles\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (W, H), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    rects = []\n",
    "\n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # filter out weak detections by ensuring the predicted\n",
    "        # probability is greater than a minimum threshold\n",
    "        if detections[0, 0, i, 2] > confidence:\n",
    "            # compute the (x, y)-coordinates of the bounding box for\n",
    "            # the object, then update the bounding box rectangles list\n",
    "            box = detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "            rects.append(box.astype(\"int\"))\n",
    "\n",
    "            # draw a bounding box surrounding the object so we can\n",
    "            # visualize it\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "    # update our centroid tracker using the computed set of bounding\n",
    "    # box rectangles\n",
    "    objects = ct.update(rects)\n",
    "\n",
    "    # loop over the tracked objects\n",
    "    for (objectID, centroid) in objects.items():\n",
    "        # draw both the ID of the object and the centroid of the\n",
    "        # object on the output frame\n",
    "        text = \"ID {}\".format(objectID)\n",
    "        cv2.putText(frame, text, (centroid[0] - 10, centroid[1] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.circle(frame, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    "\n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
